{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=32, kernel_size=2,padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64, kernel_size=2,padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64,out_channels=128, kernel_size=2,padding=1)\n",
    "        self.fc1 = nn.Linear(128, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),7))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=128, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.randn(16,1,28,28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "for i in range(10):\n",
    "    images.append(os.listdir('training/'+str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_of_img=list()\n",
    "mass_of_labels=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    for j in range(100):\n",
    "        img_grey=cv2.imread(\"training/\"+str(i)+\"/\"+images[i][j],cv2.IMREAD_GRAYSCALE)\n",
    "        thresh = 128\n",
    "        img_binary = cv2.threshold(img_grey, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "        mass_of_img.append(img_binary)\n",
    "    for k in range(100):\n",
    "        mass_of_labels.append(i)\n",
    "mass_of_imgg=np.array(mass_of_img,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "22.86054563522339\n",
      "0.02161814086139202\n",
      "17.65230917930603\n",
      "0.11731681600213051\n",
      "6.9240357875823975\n",
      "10.689756155014038\n",
      "6.984252631664276\n",
      "5.390925318002701\n",
      "9.459354400634766\n",
      "9.643970906734467\n",
      "14.078176021575928\n",
      "15.150752305984497\n",
      "17.63738751411438\n",
      "17.19473171234131\n",
      "16.576518535614014\n",
      "17.08842158317566\n",
      "17.173312187194824\n",
      "16.03010618686676\n",
      "20.485069513320923\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(mass_of_imgg)):\n",
    "        inputs=torch.Tensor(mass_of_imgg[i].astype(np.float64)).reshape(1,1,28,28)\n",
    "        labels=torch.tensor([mass_of_labels[i]], dtype=torch.int64)\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # print statistics\n",
    "        #print(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        if i % 15 == 14:    # print every 15 mini-batches\n",
    "            #print('[%d, %5d] loss: %.3f' %\n",
    "            #      (epoch + 1, i + 1, running_loss / 15))\n",
    "            running_loss = 0.0\n",
    "    print(running_loss)\n",
    "print('Finished Training')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1378, -1.3422, -1.2801, -1.0512, -0.9236, -0.4866, -0.3318, -0.4228,\n",
      "         -0.6369, -0.4629]], grad_fn=<AddmmBackward0>)\n",
      "tensor(-0.3318, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "img_grey=cv2.imread(\"training/0/9441.png\",cv2.IMREAD_GRAYSCALE)\n",
    "thresh = 128\n",
    "img_binary = cv2.threshold(img_grey, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "inputs=torch.Tensor(img_binary.astype(np.float64)).reshape(1,1,28,28)\n",
    "outputs = net(inputs)\n",
    "print(outputs)\n",
    "print(torch.max(outputs))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
