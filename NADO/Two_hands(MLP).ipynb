{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc38ffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# В РЕАЛЬНОМ ВРЕМЕНИ ОПОЗНАЕТ ЖЕСТЫ ОБЕИХ РУК (MLP) МОДЕЛЬ И MAXMASS БЕРЕТ ИЗ ФАЙЛОВ\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb90891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, *args): #получаем n массивов данных\n",
    "        cnt, labels, temp =0, [], []\n",
    "        self.data = []\n",
    "        for data in args: #выделяем по одному из них\n",
    "            self.data.extend(torch.tensor(data).type(torch.float32)) # преобразуем каждый в тензор и добавляем к общим данным\n",
    "            print(len(data))\n",
    "            for j in range(len(data)):\n",
    "                labels.append(cnt) #присовим номера каждому подмассиву для проверки\n",
    "            cnt += 1\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 2)\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x),negative_slope=0.001)\n",
    "        x = F.leaky_relu(self.fc2(x),negative_slope=0.001)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574c5e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_lmodel = \"D:/BMM/models/l_model.pth\"\n",
    "path_to_lmaxmass = \"D:/BMM/maxmasses/l_maxmass.npy\"\n",
    "path_to_rmodel = \"D:/BMM/models/r_model.pth\" \n",
    "path_to_rmaxmass = \"D:/BMM/maxmasses/r_maxmass.npy\"\n",
    "\n",
    "r_net = torch.load(path_to_rmodel) \n",
    "r_net.eval()\n",
    "l_net = torch.load(path_to_lmodel) \n",
    "l_net.eval()\n",
    "\n",
    "r_maxmass = np.load(path_to_rmaxmass, allow_pickle=True)\n",
    "l_maxmass = np.load(path_to_lmaxmass, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8a482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class handDetector():\n",
    "    def __init__(self, mode=False, maxHands=3, modelComplexity=1, detectionCon=0.5, trackCon=0.5):\n",
    "        self.mode = mode\n",
    "        self.maxHands = maxHands\n",
    "        self.modelComplexity = modelComplexity\n",
    "        self.detectionCon = detectionCon\n",
    "        self.trackCon = trackCon\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(self.mode, self.maxHands, self.modelComplexity, self.detectionCon, self.trackCon)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "    def findHands(self, img, draw=True):\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB)\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)\n",
    "        return (img , self.results.multi_hand_landmarks, self.results.multi_handedness)\n",
    "\n",
    "    def findPosition(self, img, handNo=0, draw=True):\n",
    "        xList = []\n",
    "        yList = []\n",
    "        bbox = []\n",
    "        self.lmList = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "                h, w, c = img.shape\n",
    "                cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "                xList.append(cx)\n",
    "                yList.append(cy)\n",
    "                self.lmList.append([id, cx, cy])\n",
    "                if draw:\n",
    "                    cv2.circle(img, (cx, cy), 5, (255,0,255), cv2.FILLED)\n",
    "            xmin, xmax = min(xList), max(xList)\n",
    "            ymin, ymax = min(yList), max(yList)\n",
    "            bbox = xmin, ymin, xmax, ymax\n",
    "            bbox = list(bbox)\n",
    "            a = xmax - xmin\n",
    "            b = ymax - ymin\n",
    "            if len(bbox) == 4:\n",
    "                if a >b:\n",
    "                    if bbox[0] -((a - b) //2 ) > 0:\n",
    "                        razn = (a - b) //2 \n",
    "                        bbox[3] = bbox[3] + razn\n",
    "                        bbox[0] = bbox[0] - razn           \n",
    "                else:\n",
    "                    if bbox[1] -((b - a) //2  ) > 0:\n",
    "                        razn = (b - a) //2 \n",
    "                        bbox[2] = bbox[2] + razn\n",
    "                        bbox[1] = bbox[1] - razn\n",
    "            if draw:\n",
    "                cv2.rectangle(img, (bbox[0]-20, bbox[1]-20), (bbox[2]+20, bbox[3]+20), (0, 255, 0), 2)\n",
    "        return self.lmList, bbox\n",
    "\n",
    "    def findDistance(self, p1, p2, img, draw=True):\n",
    "        x1, y1 = self.lmList[p1][1], self.lmList[p1][2]\n",
    "        x2, y2 = self.lmList[p2][1], self.lmList[p2][2]\n",
    "        cx, cy = (x1+x2)//2, (y1+y2)//2\n",
    "\n",
    "        if draw:\n",
    "            cv2.circle(img, (x1,y1), 15, (255,0,255), cv2.FILLED)\n",
    "            cv2.circle(img, (x2,y2), 15, (255,0,255), cv2.FILLED)\n",
    "            cv2.line(img, (x1,y1), (x2,y2), (255,0,255), 3)\n",
    "            cv2.circle(img, (cx,cy), 15, (255,0,255), cv2.FILLED)\n",
    "\n",
    "        length = math.hypot(x2-x1, y2-y1)\n",
    "        return length, img, [x1, y1, x2, y2, cx, cy]\n",
    "\n",
    "    def fingersUp(self):\n",
    "        fingers = []\n",
    "\n",
    "        # Thumb\n",
    "        if self.lmList[self.tipIds[0]][1] < self.lmList[self.tipIds[0]-1][1]:\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "\n",
    "        # 4 Fingers\n",
    "        for id in range(1,5):\n",
    "            if self.lmList[self.tipIds[id]][2] < self.lmList[self.tipIds[id]-2][2]:\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "        return fingers\n",
    "\n",
    "def cords_to_vers(lands, hand): #МАССИВ ИЗ 42 КООРДИНАТ В МАСИВ ПРЕДСКАЗАНИЙ ЖЕСТОВ\n",
    "    if hand == 'r':\n",
    "        net = r_net\n",
    "    elif hand == 'l':\n",
    "        net = l_net\n",
    "    pred2 = []\n",
    "    b = []\n",
    "    for id, lm in enumerate(lands.landmark):\n",
    "        h,w,c = img.shape\n",
    "        cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "        b.append(lm.x)\n",
    "        b.append(lm.y)\n",
    "        if id == 8:\n",
    "            cx8 = cx\n",
    "        if  id == 8 or id == 12:\n",
    "            cv2.circle(img, (cx,cy),10,(255,0,255),cv2.FILLED)\n",
    "    flag = 0\n",
    "    if len(b) == 42:\n",
    "        pred = net(torch.tensor(b))\n",
    "        pred2 = pred.detach().numpy()\n",
    "    else:\n",
    "        flag = 1\n",
    "    detector.mpDraw.draw_landmarks(img, lands, detector.mpHands.HAND_CONNECTIONS)\n",
    "    return(pred2, flag)\n",
    "\n",
    "def vers_to_gest(pred, flag, hand): #МАССИВ ПРЕДСКАЗАНИЙ В ЖЕСТ\n",
    "    gests = os.listdir(\"D:/BMM/datasets/\"   + hand + \"_dataset\")\n",
    "    if hand == 'r':\n",
    "        maxmass = r_maxmass\n",
    "    elif hand == 'l':\n",
    "        maxmass = l_maxmass\n",
    "    ans = 'nogest'\n",
    "    exist = [float(i) for i in pred]\n",
    "    if len(exist) == 2:\n",
    "        tempans = max(exist)\n",
    "        tempansid = exist.index(tempans)\n",
    "        if flag ==0:    \n",
    "            if tempans >= maxmass[tempansid]: # - (maxmass[tempansid])/10: #МЕТРИКИ?\n",
    "                ans = gests[tempansid][:-4]\n",
    "            else:\n",
    "                ans = 'nogest'\n",
    "    return(ans) \n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad0d81f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pTime = 0\n",
    "cTime = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = handDetector()\n",
    "j = 0\n",
    "\n",
    "while True:\n",
    "    #if j ==5:\n",
    "    #    break\n",
    "    #j+=1\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img,1) # Mirror flip  \n",
    "    img, lands, handed = detector.findHands(img)\n",
    "    lmList = detector.findPosition(img)\n",
    "    if lands:\n",
    "        if len(handed) == 2:\n",
    "            for i in handed:\n",
    "                label = MessageToDict(i)['classification'][0]['label']\n",
    "                if label == 'Left':\n",
    "                    sdvig = 20\n",
    "                    hand = 'l'\n",
    "                    if handflag == 0:\n",
    "                        jhand = lands[0]\n",
    "                    else: \n",
    "                        jhand = lands[1]\n",
    "                elif label == 'Right':\n",
    "                    sdvig = 460\n",
    "                    hand = 'r'\n",
    "                    if handflag == 0:\n",
    "                        jhand = lands[1]\n",
    "                    else: \n",
    "                        jhand = lands[0]                   \n",
    "                cords, flag = cords_to_vers(jhand,hand)\n",
    "                gest = vers_to_gest(cords, flag, hand)\n",
    "                cv2.putText(img, gest, (sdvig, 50), cv2.FONT_HERSHEY_COMPLEX, 0.9, (0, 255, 0), 2)       \n",
    "        else:\n",
    "            for i in handed:\n",
    "                label = MessageToDict(i)['classification'][0]['label']\n",
    "                if label == 'Left':\n",
    "                    handflag = 1\n",
    "                    cords, flag = cords_to_vers(lands[0],'l')\n",
    "                    gest = vers_to_gest(cords, flag, 'l')\n",
    "                    cv2.putText(img, gest, (20, 50), cv2.FONT_HERSHEY_COMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                if label == 'Right':\n",
    "                    handflag = 0\n",
    "                    cords, flag = cords_to_vers(lands[0],'r')\n",
    "                    gest = vers_to_gest(cords, flag, 'r')\n",
    "                    cv2.putText(img, gest, (460, 50), cv2.FONT_HERSHEY_COMPLEX, 0.9, (0, 255, 0), 2)      \n",
    "    cTime = time.time()\n",
    "    fps = 1. / (cTime - pTime)\n",
    "    pTime = cTime\n",
    "    cv2.putText(img, str(int(fps)), (10,90), cv2.FONT_HERSHEY_PLAIN, 3, (255,0,255), 3)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)\n",
    "    if cv2.waitKey(20) == 27: # exit on ESC\n",
    "        break\n",
    "cv2.destroyWindow(\"Image\")\n",
    "cap.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef1435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
