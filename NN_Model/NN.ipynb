{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "106a3615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os    \n",
    "import mediapipe as mp\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import time\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b686704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, *args): #получаем n массивов данных\n",
    "        cnt, labels, temp =0, [], []\n",
    "        self.data = []\n",
    "        for data in args: #выделяем по одному из них\n",
    "            self.data.extend(torch.tensor(data).type(torch.float32)) # преобразуем каждый в тензор и добавляем к общим данным\n",
    "            print(len(data))\n",
    "            for j in range(len(data)):\n",
    "                labels.append(cnt) #присовим номера каждому подмассиву для проверки\n",
    "            cnt += 1\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b66dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leftkulak.txt\n",
      "leftladon.txt\n",
      "l_arm0.txt\n",
      "rkulak.txt\n",
      "rladon.txt\n",
      "r_arm0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-184b4d701883>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(temp)\n"
     ]
    }
   ],
   "source": [
    "data, temp = [],[]\n",
    "gests = os.listdir('dataset')\n",
    "for gest in gests:\n",
    "    data = []\n",
    "    print(gest)\n",
    "    f = open('dataset/' + str(gest)).readline()\n",
    "    f = json.loads(f)\n",
    "    for i in range (len(f)):\n",
    "        '''\n",
    "        D = []\n",
    "        x = f[i][0]\n",
    "        y = f[i][1]\n",
    "        rs_x = 1 - x\n",
    "        rs_y = 1 - y\n",
    "        for j in range(0, len(f[i]), 2):\n",
    "            D.append(f[i][j] + rs_x)\n",
    "            D.append(f[i][j + 1] + rs_y)\n",
    "        '''\n",
    "        data.append(f[i])\n",
    "    temp.append(data)\n",
    "data = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021fd731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n",
      "577\n",
      "557\n",
      "956\n",
      "1375\n",
      "575\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(*data)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bed8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 6)\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x),negative_slope=0.001)\n",
    "        x = F.leaky_relu(self.fc2(x),negative_slope=0.001)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ee6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a768df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ded121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9885902244132012\n",
      "0.3045117908390239\n",
      "0.1825225792475976\n",
      "0.12501876802998596\n",
      "0.10246012363350018\n",
      "0.07506021868175594\n",
      "0.07662174387223786\n",
      "0.07008443461163552\n",
      "0.07978963340647169\n",
      "0.06621528181349276\n",
      "0.054224022781272654\n",
      "0.059562870741137884\n",
      "0.05029345959737839\n",
      "0.053970273863524196\n",
      "0.05119201993729803\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    running_loss = 0.0\n",
    "    for samples, labels in dataloader:\n",
    "        pred = net(samples)\n",
    "        loss = criterion(pred, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "    print(running_loss/len(dataloader))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4289c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975390625\n"
     ]
    }
   ],
   "source": [
    "ls=0\n",
    "for samples, labels in dataloader:\n",
    "    pred = net(samples)\n",
    "    v,i = torch.max(pred, 1)\n",
    "    ls+=torch.sum(abs(labels - i)).item()\n",
    "\n",
    "print((len(dataset)-ls)/len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "657f06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(samples)\n",
    "v,i = torch.max(pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed820ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 0, 0, 0, 4, 5, 4, 4, 4, 4, 5, 5, 3, 4, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ba41889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(labels - i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed7323ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = mp.solutions.hands.Hands(static_image_mode=False,\n",
    "                         max_num_hands=2,\n",
    "                         min_tracking_confidence=0.5,\n",
    "                         min_detection_confidence=0.5)\n",
    "\n",
    "mp_pose = mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "def img_text(img, text, pos):\n",
    "    cv2.putText(img, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6881628",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftkulak.txt\n",
    "leftladon.txt\n",
    "l_arm0.txt\n",
    "rkulak.txt\n",
    "rladon.txt\n",
    "r_arm0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfe3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#watch video\n",
    "names = ['l_fist', 'l_palm', 'l_trash', 'r_fist', 'r_palm', 'r_trash']\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    _, img = cap.read()\n",
    "    h, w, _ = img.shape\n",
    "    img = cv2.flip(img, 1)\n",
    "    # hands\n",
    "    t = time.time()\n",
    "    result = hands.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    hand_time = time.time() - t\n",
    "   \n",
    "    if result.multi_hand_landmarks:\n",
    "        for_model = []\n",
    "        for id, lm in enumerate(result.multi_hand_landmarks[0].landmark):\n",
    "            cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "            cv2.circle(img, (cx, cy), 5, (0, 255, 0))\n",
    "            for_model.append(lm.x)\n",
    "            for_model.append(lm.y)\n",
    "        for_model = torch.tensor([for_model]).type(torch.float)\n",
    "        pred = net(for_model)\n",
    "        v,i = torch.max(pred, 1)\n",
    "        img_text(img, str(names[i.item()]), (100, 30))\n",
    "        if(i.item == 4):\n",
    "            pyautogui.press('space') \n",
    "    cv2.imshow(\"1\",img)\n",
    "    if cv2.waitKey(1)>-1:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d948705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3c78406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ea051",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
