{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106a3615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os    \n",
    "import torch.nn.functional as F\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b686704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, *args): #получаем n массивов данных\n",
    "        cnt, labels, temp =0, [], []\n",
    "        self.data = []\n",
    "        for data in args: #выделяем по одному из них\n",
    "            self.data.extend(torch.tensor(data).type(torch.float32)) # преобразуем каждый в тензор и добавляем к общим данным\n",
    "            print(len(data))\n",
    "            for j in range(len(data)):\n",
    "                labels.append(cnt) #присовим номера каждому подмассиву для проверки\n",
    "            cnt += 1\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6954b1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686\n"
     ]
    }
   ],
   "source": [
    "f = open('dataset/stop2.txt').readline()\n",
    "f = json.loads(f)\n",
    "print(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e66c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "883\n"
     ]
    }
   ],
   "source": [
    "f = open('dataset/kulaksgat2.txt').readline()\n",
    "f = json.loads(f)\n",
    "print(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4586c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4,5,6][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b66dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kulaksgat2.txt\n",
      "stop2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/05/318hv04n4zg2jytwsxm19nsw0000gn/T/ipykernel_45129/687087349.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(temp)\n"
     ]
    }
   ],
   "source": [
    "data, temp = [],[]\n",
    "gests = os.listdir('dataset')\n",
    "for gest in gests:\n",
    "    data = []\n",
    "    print(gest)\n",
    "    f = open('dataset/' + str(gest)).readline()\n",
    "    f = json.loads(f)\n",
    "    for i in range (len(f)):\n",
    "        data.append(f[i])\n",
    "    temp.append(data)\n",
    "data = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "021fd731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "883\n",
      "686\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(*data)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bed8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.fc3 = nn.Linear(200, 32)\n",
    "        self.fc4 = nn.Linear(32, 2)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ee6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a768df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ded121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.337959557715635\n",
      "0.0007921106121671073\n",
      "0.0006690958229569333\n",
      "0.0005548262881234223\n",
      "0.0004605078979693644\n",
      "0.0003989845144189985\n",
      "0.00032010758990708155\n",
      "0.0002704216806819204\n",
      "0.00022861767585169446\n",
      "0.00019578399484743159\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for samples, labels in dataloader:\n",
    "        #print(samples,labels)\n",
    "        pred = net(samples)\n",
    "        loss = criterion(pred, labels)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "    print(running_loss)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85f4d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=torch.tensor([0.41655007004737854, 0.7089771032333374, 0.4633732736110687, 0.6954310536384583, 0.5125848650932312, 0.6476010084152222, 0.5015125274658203, 0.592243492603302, 0.4613598585128784, 0.5826143026351929, 0.5011842250823975, 0.5836077928543091, 0.509346067905426, 0.5467285513877869, 0.49322056770324707, 0.5981612205505371, 0.48973703384399414, 0.6084542870521545, 0.47082626819610596, 0.5737633109092712, 0.47700440883636475, 0.5433168411254883, 0.46477067470550537, 0.6013384461402893, 0.46333837509155273, 0.599715530872345, 0.4406990706920624, 0.571521520614624, 0.44218024611473083, 0.5451012849807739, 0.436707079410553, 0.6007078289985657, 0.4390093982219696, 0.6013930439949036, 0.4080536961555481, 0.5698967576026917, 0.4114087224006653, 0.549913763999939, 0.41262519359588623, 0.5887411832809448, 0.41415098309516907, 0.5954364538192749])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7c542dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4166, 0.7090, 0.4634, 0.6954, 0.5126, 0.6476, 0.5015, 0.5922, 0.4614,\n",
       "        0.5826, 0.5012, 0.5836, 0.5093, 0.5467, 0.4932, 0.5982, 0.4897, 0.6085,\n",
       "        0.4708, 0.5738, 0.4770, 0.5433, 0.4648, 0.6013, 0.4633, 0.5997, 0.4407,\n",
       "        0.5715, 0.4422, 0.5451, 0.4367, 0.6007, 0.4390, 0.6014, 0.4081, 0.5699,\n",
       "        0.4114, 0.5499, 0.4126, 0.5887, 0.4142, 0.5954])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24133122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.1436, -9.2897], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2080f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    net(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50342872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d1d775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f5f9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b401c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76f1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
