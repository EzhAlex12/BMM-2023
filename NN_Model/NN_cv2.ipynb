{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os    \n",
    "import mediapipe as mp\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import time\n",
    "import webbrowser\n",
    "import keyboard\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, *args): #получаем n массивов данных\n",
    "        cnt, labels, temp =0, [], []\n",
    "        self.data = []\n",
    "        for data in args: #выделяем по одному из них\n",
    "            self.data.extend(torch.tensor(data).type(torch.float32)) # преобразуем каждый в тензор и добавляем к общим данным\n",
    "            print(len(data))\n",
    "            for j in range(len(data)):\n",
    "                labels.append(cnt) #присовим номера каждому подмассиву для проверки\n",
    "            cnt += 1\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_ladon_d.txt\n",
      "r_kulak_d.txt\n",
      "l_ladon_d2.txt\n",
      "thrashhhh3.txt\n",
      "l_kulak_d.txt\n"
     ]
    }
   ],
   "source": [
    "data, temp = [],[]\n",
    "gests = os.listdir('dataset3')\n",
    "for gest in gests:\n",
    "    data = []\n",
    "    print(gest)\n",
    "    f = open('dataset3/' + str(gest)).readline()\n",
    "    f = json.loads(f)\n",
    "    for i in range (len(f)):\n",
    "        data.append(f[i])\n",
    "    temp.append(data)\n",
    "data = np.array(temp,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "2001\n",
      "2001\n",
      "4502\n",
      "2001\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(*data)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 5)\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x),negative_slope=0.001)\n",
    "        x = F.leaky_relu(self.fc2(x),negative_slope=0.001)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6598586987256242\n",
      "0.3345378628357902\n",
      "0.2660977666140022\n",
      "0.22993108401398943\n",
      "0.1963340534311731\n",
      "0.17544403980674264\n",
      "0.15992750090492122\n",
      "0.14322260297510936\n",
      "0.13625736719192674\n",
      "0.123158838062802\n",
      "0.10960475592031207\n",
      "0.12331326410669805\n",
      "0.11360693463931798\n",
      "0.10266511787659229\n",
      "0.104391990443114\n",
      "0.09416241394198092\n",
      "0.09078101822859286\n",
      "0.09002300433140448\n",
      "0.08765232667867023\n",
      "0.0930804383351177\n",
      "0.08209920426643968\n",
      "0.08530583390829098\n",
      "0.08172531673893728\n",
      "0.07931659945249296\n",
      "0.07442337484701889\n",
      "0.0675808388874997\n",
      "0.07924668297554632\n",
      "0.06412043780058055\n",
      "0.07194981782551547\n",
      "0.07779910623655974\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    for samples, labels in dataloader:\n",
    "        pred = net(samples)\n",
    "        loss = criterion(pred, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "    print(running_loss/len(dataloader))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9698544698544699\n"
     ]
    }
   ],
   "source": [
    "ls=0\n",
    "for samples, labels in dataloader:\n",
    "    pred = net(samples)\n",
    "    v,i = torch.max(pred, 1)\n",
    "    ls+=torch.sum(abs(labels - i)).item()\n",
    "\n",
    "print((len(dataset)-ls)/len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(samples)\n",
    "v,i = torch.max(pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "hands = mp.solutions.hands.Hands(static_image_mode=False,\n",
    "                         max_num_hands=2,\n",
    "                         min_tracking_confidence=0.5,\n",
    "                         min_detection_confidence=0.5)\n",
    "\n",
    "mp_pose = mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "def img_text(img, text, pos):\n",
    "    cv2.putText(img, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ladon_d.txt\n",
    "r_kulak_d.txt\n",
    "l_ladon_d2.txt\n",
    "thrashhhh3.txt\n",
    "l_kulak_d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thrash\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "thrash\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_kulak\n",
      "l_kulak\n",
      "r_ladon\n",
      "r_ladon\n",
      "r_kulak\n",
      "r_kulak\n",
      "r_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_kulak\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_kulak\n",
      "l_ladon\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "l_ladon\n",
      "l_kulak\n"
     ]
    }
   ],
   "source": [
    "#watch video\n",
    "names = ['r_ladon', 'r_kulak', 'l_ladon','thrash','l_kulak']\n",
    "cap = cv2.VideoCapture(0)\n",
    "cnt_iter=[]\n",
    "check=True\n",
    "check_arr=[]\n",
    "set_play_pos=True\n",
    "while(True):\n",
    "    _, img = cap.read()\n",
    "    h, w, _ = img.shape\n",
    "    img = cv2.flip(img, 1)\n",
    "    # hands\n",
    "    t = time.time()\n",
    "    result = hands.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    hand_time = time.time() - t\n",
    "   \n",
    "    if result.multi_hand_landmarks:\n",
    "        for_model = []\n",
    "        for id, lm in enumerate(result.multi_hand_landmarks[0].landmark):\n",
    "            cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "            cv2.circle(img, (cx, cy), 5, (0, 255, 0))\n",
    "            for_model.append(lm.x)\n",
    "            for_model.append(lm.y)\n",
    "        for_model = torch.tensor([for_model]).type(torch.float)\n",
    "        pred = net(for_model)\n",
    "        v,i = torch.max(pred, 1)\n",
    "        img_text(img, str(names[i.item()]), (100, 30))\n",
    "        cnt_iter.append(i.item())\n",
    "        check_arr.append(i.item())\n",
    "        if len(cnt_iter)==5:\n",
    "            vals, counts = np.unique(cnt_iter, return_counts=True)\n",
    "            #print(vals[np.argmax(counts)])\n",
    "            cnt_iter=[]\n",
    "            if check==True:\n",
    "                match int(vals[np.argmax(counts)]):\n",
    "                    case 0:\n",
    "                        webbrowser.open(\"https://www.youtube.com/watch?v=dQw4w9WgXcQ&ab_channel=RickAstley\")\n",
    "                        print('r_ladon')\n",
    "                        check=False\n",
    "                    case 1:\n",
    "                        webbrowser.open(\"https://www.youtube.com/watch?v=A1Qb4zfurA8&ab_channel=Enjoykipip\")\n",
    "                        print('r_kulak')\n",
    "                        check=False\n",
    "                    case 2:\n",
    "                        print('l_ladon')\n",
    "                        if set_play_pos==True:\n",
    "                            keyboard.send(\"space\")\n",
    "                            set_play_pos=False\n",
    "                        check=False\n",
    "                    case 3:\n",
    "                        print('thrash')\n",
    "                    case 4:\n",
    "                        print('l_kulak')\n",
    "                        if set_play_pos==False:\n",
    "                            keyboard.send(\"space\");\n",
    "                            set_play_pos=True\n",
    "                        check=False\n",
    "            else:\n",
    "                if len(check_arr)>=10:\n",
    "                    check=True\n",
    "                    check_arr=[]\n",
    "        \n",
    "\n",
    "    cv2.imshow(\"1\",img)\n",
    "    if cv2.waitKey(1)>-1:\n",
    "        break\n",
    "     \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['r_ladon', 'r_kulak', 'l_ladon','thrash','l_kulak']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
