{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os    \n",
    "import mediapipe as mp\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import time\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, *args): #получаем n массивов данных\n",
    "        cnt, labels, temp =0, [], []\n",
    "        self.data = []\n",
    "        for data in args: #выделяем по одному из них\n",
    "            self.data.extend(torch.tensor(data).type(torch.float32)) # преобразуем каждый в тензор и добавляем к общим данным\n",
    "            print(len(data))\n",
    "            for j in range(len(data)):\n",
    "                labels.append(cnt) #присовим номера каждому подмассиву для проверки\n",
    "            cnt += 1\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_ladon_d.txt\n",
      "r_kulak_d.txt\n",
      "l_ladon_d2.txt\n",
      "thrashhhh3.txt\n",
      "l_kulak_d.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/05/318hv04n4zg2jytwsxm19nsw0000gn/T/ipykernel_95053/2590571185.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(temp)\n"
     ]
    }
   ],
   "source": [
    "data, temp = [],[]\n",
    "gests = os.listdir('dataset3')\n",
    "for gest in gests:\n",
    "    data = []\n",
    "    print(gest)\n",
    "    f = open('dataset3/' + str(gest)).readline()\n",
    "    f = json.loads(f)\n",
    "    for i in range (len(f)):\n",
    "        data.append(f[i])\n",
    "    temp.append(data)\n",
    "data = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "2001\n",
      "2001\n",
      "4502\n",
      "2001\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(*data)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 5)\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x),negative_slope=0.001)\n",
    "        x = F.leaky_relu(self.fc2(x),negative_slope=0.001)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6509328420509768\n",
      "0.33493015647429947\n",
      "0.26451030235184964\n",
      "0.22739828261249054\n",
      "0.19307303244290908\n",
      "0.17444446122350024\n",
      "0.15662529330421954\n",
      "0.13608195738571569\n",
      "0.13379378608860257\n",
      "0.128684342627728\n",
      "0.1143706835740272\n",
      "0.11063255494802265\n",
      "0.11113189099817429\n",
      "0.09678918603361678\n",
      "0.10106656740716113\n",
      "0.09317130460846\n",
      "0.08989088947329756\n",
      "0.09165989423898356\n",
      "0.08125491358142982\n",
      "0.08446041612422613\n",
      "0.08141254151955751\n",
      "0.08310880028749006\n",
      "0.07519923558327979\n",
      "0.07666147885285444\n",
      "0.07338326678862479\n",
      "0.068069689679625\n",
      "0.0722365702476824\n",
      "0.06410991322129744\n",
      "0.0651138779451236\n",
      "0.07423277714744816\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    for samples, labels in dataloader:\n",
    "        pred = net(samples)\n",
    "        loss = criterion(pred, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "    print(running_loss/len(dataloader))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9136414521029905\n"
     ]
    }
   ],
   "source": [
    "ls=0\n",
    "for samples, labels in dataloader:\n",
    "    pred = net(samples)\n",
    "    v,i = torch.max(pred, 1)\n",
    "    ls+=torch.sum(abs(labels - i)).item()\n",
    "\n",
    "print((len(dataset)-ls)/len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(samples)\n",
    "v,i = torch.max(pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "hands = mp.solutions.hands.Hands(static_image_mode=False,\n",
    "                         max_num_hands=2,\n",
    "                         min_tracking_confidence=0.5,\n",
    "                         min_detection_confidence=0.5)\n",
    "\n",
    "mp_pose = mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "def img_text(img, text, pos):\n",
    "    cv2.putText(img, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ladon_d.txt\n",
    "r_kulak_d.txt\n",
    "l_ladon_d2.txt\n",
    "thrashhhh3.txt\n",
    "l_kulak_d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_ladon\n",
      "r_ladon\n",
      "r_ladon\n",
      "r_ladon\n",
      "r_ladon\n",
      "r_kulak\n",
      "r_kulak\n",
      "r_kulak\n",
      "r_kulak\n",
      "r_kulak\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "r_ladon\n",
      "r_ladon\n",
      "r_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "r_ladon\n",
      "thrash\n",
      "thrash\n",
      "r_kulak\n",
      "r_kulak\n",
      "thrash\n",
      "thrash\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "r_kulak\n",
      "r_kulak\n",
      "r_kulak\n",
      "r_ladon\n",
      "r_ladon\n",
      "r_ladon\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "r_ladon\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "thrash\n",
      "thrash\n",
      "l_kulak\n",
      "thrash\n",
      "r_ladon\n",
      "r_ladon\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "l_ladon\n",
      "l_ladon\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "l_ladon\n",
      "l_ladon\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "l_ladon\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "l_ladon\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "r_ladon\n",
      "thrash\n",
      "thrash\n",
      "l_ladon\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "r_ladon\n",
      "thrash\n",
      "thrash\n",
      "l_ladon\n",
      "l_ladon\n",
      "r_ladon\n",
      "r_ladon\n",
      "l_ladon\n",
      "r_ladon\n",
      "r_ladon\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "l_kulak\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "thrash\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "l_kulak\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n",
      "thrash\n"
     ]
    }
   ],
   "source": [
    "#watch video\n",
    "names = ['r_ladon', 'r_kulak', 'l_ladon','thrash','l_kulak']\n",
    "cap = cv2.VideoCapture(0)\n",
    "cnt_iter=[]\n",
    "while(True):\n",
    "    _, img = cap.read()\n",
    "    ch=0\n",
    "    h, w, _ = img.shape\n",
    "    img = cv2.flip(img, 1)\n",
    "    # hands\n",
    "    t = time.time()\n",
    "    result = hands.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    hand_time = time.time() - t\n",
    "   \n",
    "    if result.multi_hand_landmarks:\n",
    "        for_model = []\n",
    "        for id, lm in enumerate(result.multi_hand_landmarks[0].landmark):\n",
    "            cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "            cv2.circle(img, (cx, cy), 5, (0, 255, 0))\n",
    "            for_model.append(lm.x)\n",
    "            for_model.append(lm.y)\n",
    "        for_model = torch.tensor([for_model]).type(torch.float)\n",
    "        pred = net(for_model)\n",
    "        v,i = torch.max(pred, 1)\n",
    "        img_text(img, str(names[i.item()]), (100, 30))\n",
    "        cnt_iter.append(i.item())\n",
    "        if len(cnt_iter)==5:\n",
    "            vals, counts = np.unique(cnt_iter, return_counts=True)\n",
    "            #print(vals[np.argmax(counts)])\n",
    "            cnt_iter=[]\n",
    "            match int(vals[np.argmax(counts)]):\n",
    "                case 0:\n",
    "                    print('r_ladon')\n",
    "                case 1:\n",
    "                    print('r_kulak')\n",
    "                case 2:\n",
    "                    print('l_ladon')\n",
    "                case 3:\n",
    "                    print('thrash')\n",
    "                case 4:\n",
    "                    print('l_kulak')\n",
    "\n",
    "    cv2.imshow(\"1\",img)\n",
    "    if cv2.waitKey(1)>-1:\n",
    "        break\n",
    "     \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['r_ladon', 'r_kulak', 'l_ladon','thrash','l_kulak']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
