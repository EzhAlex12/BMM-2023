{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os    \n",
    "import mediapipe as mp\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import time\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, *args): #получаем n массивов данных\n",
    "        cnt, labels, temp =0, [], []\n",
    "        self.data = []\n",
    "        for data in args: #выделяем по одному из них\n",
    "            self.data.extend(torch.tensor(data).type(torch.float32)) # преобразуем каждый в тензор и добавляем к общим данным\n",
    "            print(len(data))\n",
    "            for j in range(len(data)):\n",
    "                labels.append(cnt) #присовим номера каждому подмассиву для проверки\n",
    "            cnt += 1\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkulak.txt\n",
      "r_arm0.txt\n",
      "leftladon.txt\n",
      "l_arm0.txt\n",
      "rladon.txt\n",
      "leftkulak.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/05/318hv04n4zg2jytwsxm19nsw0000gn/T/ipykernel_74297/199723171.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(temp)\n"
     ]
    }
   ],
   "source": [
    "data, temp = [],[]\n",
    "gests = os.listdir('dataset')\n",
    "for gest in gests:\n",
    "    data = []\n",
    "    print(gest)\n",
    "    f = open('dataset/' + str(gest)).readline()\n",
    "    f = json.loads(f)\n",
    "    for i in range (len(f)):\n",
    "        '''\n",
    "        D = []\n",
    "        x = f[i][0]\n",
    "        y = f[i][1]\n",
    "        rs_x = 1 - x\n",
    "        rs_y = 1 - y\n",
    "        for j in range(0, len(f[i]), 2):\n",
    "            D.append(f[i][j] + rs_x)\n",
    "            D.append(f[i][j + 1] + rs_y)\n",
    "        '''\n",
    "        data.append(f[i])\n",
    "    temp.append(data)\n",
    "data = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956\n",
      "575\n",
      "577\n",
      "557\n",
      "1375\n",
      "1080\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(*data)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 6)\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x),negative_slope=0.001)\n",
    "        x = F.leaky_relu(self.fc2(x),negative_slope=0.001)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9423485176637769\n",
      "0.29414664157666265\n",
      "0.1779397435253486\n",
      "0.12436659923114349\n",
      "0.09121893866395112\n",
      "0.09436145436193329\n",
      "0.07494178165434277\n",
      "0.06437826119654347\n",
      "0.07131152947986266\n",
      "0.06341222729024594\n",
      "0.06133147420041496\n",
      "0.07010080727159221\n",
      "0.04912965462390275\n",
      "0.049001203283114594\n",
      "0.05089004646633839\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    running_loss = 0.0\n",
    "    for samples, labels in dataloader:\n",
    "        pred = net(samples)\n",
    "        loss = criterion(pred, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "    print(running_loss/len(dataloader))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92734375\n"
     ]
    }
   ],
   "source": [
    "ls=0\n",
    "for samples, labels in dataloader:\n",
    "    pred = net(samples)\n",
    "    v,i = torch.max(pred, 1)\n",
    "    ls+=torch.sum(abs(labels - i)).item()\n",
    "\n",
    "print((len(dataset)-ls)/len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(samples)\n",
    "v,i = torch.max(pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "hands = mp.solutions.hands.Hands(static_image_mode=False,\n",
    "                         max_num_hands=2,\n",
    "                         min_tracking_confidence=0.5,\n",
    "                         min_detection_confidence=0.5)\n",
    "\n",
    "mp_pose = mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "def img_text(img, text, pos):\n",
    "    cv2.putText(img, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mПри выполнении кода в текущей ячейке или предыдущей ячейке ядро аварийно завершило работу. Проверьте код в ячейках, чтобы определить возможную причину сбоя. Щелкните <a href=\"https://aka.ms/vscodeJupyterKernelCrash\">здесь</a> для получения дополнительных сведений. Подробнее см. в <a href='command:jupyter.viewOutput'>журнале Jupyter</a>."
     ]
    }
   ],
   "source": [
    "#watch video\n",
    "names = ['r_kulak', 'r_thrash', 'l_ladon', 'l_thrash', 'r_ladon', 'l_kulak']\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    _, img = cap.read()\n",
    "    h, w, _ = img.shape\n",
    "    img = cv2.flip(img, 1)\n",
    "    # hands\n",
    "    t = time.time()\n",
    "    result = hands.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    hand_time = time.time() - t\n",
    "   \n",
    "    if result.multi_hand_landmarks:\n",
    "        for_model = []\n",
    "        for id, lm in enumerate(result.multi_hand_landmarks[0].landmark):\n",
    "            cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "            cv2.circle(img, (cx, cy), 5, (0, 255, 0))\n",
    "            for_model.append(lm.x)\n",
    "            for_model.append(lm.y)\n",
    "        for_model = torch.tensor([for_model]).type(torch.float)\n",
    "        pred = net(for_model)\n",
    "        v,i = torch.max(pred, 1)\n",
    "        img_text(img, str(names[i.item()]), (100, 30))\n",
    "        if(i.item == 4):\n",
    "            pyautogui.press('space') \n",
    "    cv2.imshow(\"1\",img)\n",
    "    if cv2.waitKey(1)>-1:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
