{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106a3615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "import pyautogui as pag\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import os\n",
    "import sys  # zahvat\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os    \n",
    "import torch.nn.functional as F\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b686704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, *args): #получаем n массивов данных\n",
    "        cnt, labels, temp =0, [], []\n",
    "        self.data = []\n",
    "        for data in args: #выделяем по одному из них\n",
    "            self.data.extend(torch.tensor(data).type(torch.float32)) # преобразуем каждый в тензор и добавляем к общим данным\n",
    "#             print(len(data))\n",
    "            for j in range(len(data)):\n",
    "                labels.append(cnt) #присовим номера каждому подмассиву для проверки\n",
    "            cnt += 1\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bed8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.fc3 = nn.Linear(200, 32)\n",
    "        self.fc4 = nn.Linear(32, 2)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50342872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gesture = {0: \"Fist\",\n",
    "           1:\"Open palm\",\n",
    "           2:\"Окей\",\n",
    "           3:\"Жест 4\",\n",
    "          4:\"Жест 5\",\n",
    "          5:\"Жест 6\"}\n",
    "\n",
    "def Result_chek(neuro_res):\n",
    "    znak_num=len(neuro_res)\n",
    "    global gesture\n",
    "    answ = {}\n",
    "    for el in range(znak_num):\n",
    "        answ[el] = neuro_res[el]\n",
    "    res = answ.keys()\n",
    "#     print(answ.keys())\n",
    "#     print(list(answ.values()).index(max(neuro_res)))\n",
    "#     print(list(answ.keys())[list(answ.values()).index(max(neuro_res))])\n",
    "    return gesture[list(answ.values()).index(max(neuro_res))]#(\"Жест на экране:  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e66c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('dataset/stop2.txt').readline()\n",
    "f = json.loads(f)\n",
    "# print(len(f))\n",
    "\n",
    "f = open('dataset/kulaksgat2.txt').readline()\n",
    "f = json.loads(f)\n",
    "# print(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b66dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, temp = [],[]\n",
    "gests = os.listdir('dataset')\n",
    "for gest in gests:\n",
    "    data = []\n",
    "#     print(gest)\n",
    "    f = open('dataset/' + str(gest)).readline()\n",
    "    f = json.loads(f)\n",
    "    for i in range (len(f)):\n",
    "        data.append(f[i])\n",
    "    temp.append(data)\n",
    "data = np.array(temp, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "021fd731",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(*data)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d80510f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training 1.0371203995607203e-05\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for samples, labels in dataloader:\n",
    "        #print(samples,labels)\n",
    "        pred = net(samples)\n",
    "        loss = criterion(pred, labels)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "#     print(running_loss)\n",
    "print('Finished Training', running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4292e7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 1920 ----\n",
      "Point(x=794, y=398)\n",
      "Point(x=850, y=476)\n",
      "Point(x=906, y=554)\n",
      "Point(x=962, y=632)\n",
      "Point(x=1018, y=710)\n",
      "Point(x=1074, y=788)\n",
      "Point(x=1056, y=779)\n",
      "Point(x=1038, y=770)\n",
      "Point(x=1020, y=761)\n",
      "Point(x=1002, y=752)\n",
      "Point(x=984, y=743)\n",
      "Point(x=991, y=745)\n",
      "Point(x=998, y=747)\n",
      "Point(x=1005, y=749)\n",
      "Point(x=1012, y=751)\n",
      "Point(x=1019, y=753)\n",
      "Point(x=1093, y=743)\n",
      "Point(x=1167, y=733)\n",
      "Point(x=1241, y=723)\n",
      "Point(x=1315, y=713)\n",
      "Point(x=1389, y=703)\n",
      "Point(x=1401, y=674)\n",
      "Point(x=1413, y=645)\n",
      "Point(x=1425, y=616)\n",
      "Point(x=1437, y=587)\n",
      "Point(x=1449, y=558)\n",
      "Point(x=1451, y=559)\n",
      "Point(x=1453, y=560)\n",
      "Point(x=1455, y=561)\n",
      "Point(x=1457, y=562)\n",
      "Point(x=1459, y=563)\n",
      "Point(x=1462, y=556)\n",
      "Point(x=1465, y=549)\n",
      "Point(x=1468, y=542)\n",
      "Point(x=1471, y=535)\n",
      "Point(x=1474, y=528)\n",
      "Point(x=1451, y=514)\n",
      "Point(x=1428, y=500)\n",
      "Point(x=1405, y=486)\n",
      "Point(x=1382, y=472)\n",
      "Point(x=1359, y=458)\n",
      "Point(x=1373, y=464)\n",
      "Point(x=1387, y=470)\n",
      "Point(x=1401, y=476)\n",
      "Point(x=1415, y=482)\n",
      "Point(x=1429, y=488)\n",
      "Point(x=1373, y=462)\n",
      "Point(x=1317, y=436)\n",
      "Point(x=1261, y=410)\n",
      "Point(x=1205, y=384)\n",
      "Point(x=1149, y=358)\n",
      "Point(x=1177, y=359)\n",
      "Point(x=1205, y=360)\n",
      "Point(x=1233, y=361)\n",
      "Point(x=1261, y=362)\n",
      "Point(x=1289, y=363)\n",
      "Point(x=1227, y=449)\n",
      "Point(x=1165, y=535)\n",
      "Point(x=1103, y=621)\n",
      "Point(x=1041, y=707)\n",
      "Point(x=979, y=793)\n",
      "Point(x=976, y=761)\n",
      "Point(x=973, y=729)\n",
      "Point(x=970, y=697)\n",
      "Point(x=967, y=665)\n",
      "Point(x=964, y=633)\n",
      "Point(x=972, y=583)\n",
      "Point(x=980, y=533)\n",
      "Point(x=988, y=483)\n",
      "Point(x=996, y=433)\n",
      "Point(x=1004, y=383)\n",
      "Point(x=1000, y=416)\n",
      "Point(x=996, y=449)\n",
      "Point(x=992, y=482)\n",
      "Point(x=988, y=515)\n",
      "Point(x=984, y=548)\n",
      "Point(x=1020, y=533)\n",
      "Point(x=1056, y=518)\n",
      "Point(x=1092, y=503)\n",
      "Point(x=1128, y=488)\n",
      "Point(x=1164, y=473)\n",
      "Point(x=1151, y=441)\n",
      "Point(x=1138, y=409)\n",
      "Point(x=1125, y=377)\n",
      "Point(x=1112, y=345)\n",
      "Point(x=1099, y=313)\n",
      "Point(x=1091, y=332)\n",
      "Point(x=1083, y=351)\n",
      "Point(x=1075, y=370)\n",
      "Point(x=1067, y=389)\n",
      "Point(x=1059, y=408)\n",
      "Point(x=1008, y=398)\n",
      "Point(x=957, y=388)\n",
      "Point(x=906, y=378)\n",
      "Point(x=855, y=368)\n",
      "Point(x=804, y=358)\n",
      "Point(x=797, y=350)\n",
      "Point(x=790, y=342)\n",
      "Point(x=783, y=334)\n",
      "Point(x=776, y=326)\n",
      "Point(x=769, y=318)\n",
      "Point(x=755, y=368)\n",
      "Point(x=741, y=418)\n",
      "Point(x=727, y=468)\n",
      "Point(x=713, y=518)\n",
      "Point(x=699, y=568)\n",
      "Point(x=716, y=622)\n",
      "Point(x=733, y=676)\n",
      "Point(x=750, y=730)\n",
      "Point(x=767, y=784)\n",
      "Point(x=784, y=838)\n",
      "Point(x=847, y=838)\n",
      "Point(x=910, y=838)\n",
      "Point(x=973, y=838)\n",
      "Point(x=1036, y=838)\n",
      "Point(x=1099, y=838)\n",
      "Point(x=1113, y=835)\n",
      "Point(x=1127, y=832)\n",
      "Point(x=1141, y=829)\n",
      "Point(x=1155, y=826)\n",
      "Point(x=1169, y=823)\n",
      "Point(x=1261, y=806)\n",
      "Point(x=1353, y=789)\n",
      "Point(x=1445, y=772)\n",
      "Point(x=1537, y=755)\n",
      "Point(x=1629, y=738)\n",
      "Point(x=1624, y=729)\n",
      "Point(x=1619, y=720)\n",
      "Point(x=1614, y=711)\n",
      "Point(x=1609, y=702)\n"
     ]
    }
   ],
   "source": [
    "import tkinter\n",
    "import pyautogui as pag\n",
    "import cv2\n",
    "import keyboard\n",
    "cap = cv2.VideoCapture(0) \n",
    "cap.set(3, 640) # Width\n",
    "cap.set(4, 480) # Lenght\n",
    "cap.set(10, 100) # Brightness\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(False)\n",
    "\n",
    "sensetive = 0.5\n",
    "    \n",
    "weigth, height = pag.size()\n",
    "print(\"-----\",weigth,\"----\")\n",
    "koef = [weigth*sensetive,height*sensetive]\n",
    "pred_x, pred_y, now_x, now_y = 0,0,0,0    \n",
    "success, img = cap.read()\n",
    "img = cv2.flip(img,1) # Mirror flip\n",
    "cx8=0\n",
    "imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "results = hands.process(imgRGB)\n",
    "if results.multi_hand_landmarks:\n",
    "    print(results.multi_hand_landmarks[8])\n",
    "    for handLms in results.multi_hand_landmarks:\n",
    "        try:\n",
    "            lm = handLms.landmark[8]\n",
    "            now_x, now_y = lm.x, lm.y\n",
    "        except IndexErrror:\n",
    "            pass\n",
    "\n",
    "        \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img,1) # Mirror flip\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "            lm = handLms.landmark[8]\n",
    "            now_x, now_y = lm.x, lm.y\n",
    "            x,y = pred_x - now_x,  now_y - pred_y \n",
    "            \n",
    "            #func place\n",
    "            try:\n",
    "                smooth_mouse(now_x, now_y, pred_x, pred_y, koef)\n",
    "            except BaseException:\n",
    "                print(\"out of border\")\n",
    "#                 cap.release()\n",
    "#                 cv2.waitKey(1)   \n",
    "#                 break\n",
    "                pag.moveTo(1000,500)\n",
    "            pred_x, pred_y = now_x, now_y\n",
    "    if keyboard.is_pressed('esc'):  # if key 'esc' is pressed\n",
    "        cap.release()\n",
    "        cv2.waitKey(1)   \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7048e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_mouse(x,y, ox, oy, sens):\n",
    "    speed_x = x - ox if x - ox > 0 else ox - x\n",
    "    speed_y = y - oy if y - oy > 0 else oy- y\n",
    "    dur = 1 - (max(speed_y, speed_x))\n",
    "#     print(sens)\n",
    "    shift = (x-ox) * sens[0], (y - oy) * sens[1]\n",
    "#     print(shift)\n",
    "    for i in range(5):\n",
    "        print(pag.position())\n",
    "        pag.moveTo(shift[0]//5 + pag.position()[0], shift[1]//5 + pag.position()[1])\n",
    "#     pag.moveTo(shift[0], shift[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_mouse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457ded8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "72b401c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import os\n",
    "import sys \n",
    "\n",
    "\n",
    "# Подключаем камеру\n",
    "cap = cv2.VideoCapture(0) \n",
    "cap.set(3, 640) # Width\n",
    "cap.set(4, 480) # Lenght\n",
    "cap.set(10, 100) # Brightness\n",
    "\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(False)\n",
    "npDraw = mp.solutions.drawing_utils\n",
    "a = []\n",
    "pTime = 0\n",
    "cTime = 0\n",
    "data = []\n",
    " #Зацикливаем получение кадров от камеры\n",
    "while True: \n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img,1) # Mirror flip\n",
    "    cx8=0\n",
    "    imgRGB = img#cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    pred2 = []\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "#             print(\"handLms  \", handLms.landmark[1])\n",
    "            b = []\n",
    "            for id, lm in enumerate(handLms.landmark):\n",
    "                h,w,c = img.shape\n",
    "                cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "                b.append(lm.x)\n",
    "                b.append(lm.y)\n",
    "                if id == 8:\n",
    "                    cx8 = cx\n",
    "                # print(id, lm)\n",
    "                if  id == 8: #id == 12\n",
    "                    cv2.circle(img, (cx,cy),10,(255,0,255),cv2.FILLED)\n",
    "            if len(b) == 42:\n",
    "                pred = net(torch.tensor(b))\n",
    "                pred2 = pred.detach().numpy()\n",
    "            cv2.putText(img, Result_chek(net(torch.tensor(b))), (200,30), cv2.FONT_HERSHEY_PLAIN,2, (25,20,0),2)\n",
    "            npDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)\n",
    "            a. append(b)\n",
    "            \n",
    "    \n",
    "\n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime\n",
    "    exist = [float(i) for i in pred2]\n",
    "#     cv2.putText(img, str(exist),(10,30), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0), 2) # ФреймРейт\n",
    "#     cv2.putText(img, str(cx8),(100,30), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0), 2)\n",
    "    cv2.imshow('python', img)\n",
    "    if cv2.waitKey(20) == 27: # exit on ESC\n",
    "        break\n",
    "        \n",
    "cv2.destroyWindow(\"python\")\n",
    "cap.release()\n",
    "cv2.waitKey(1)\n",
    "# print(a) # a is massive of data we need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633464e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
